{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8210b19",
   "metadata": {},
   "source": [
    "## A.I. Assignment 5\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "By the end of this lab, you should be able to:\n",
    "* Get more familiar with tensors in pytorch \n",
    "* Create a simple multilayer perceptron model with pytorch\n",
    "* Visualise the parameters\n",
    "\n",
    "\n",
    "### Task\n",
    "\n",
    "Build a fully connected feed forward network that adds two bits. Determine the a propper achitecture for this network (what database you use for this problem? how many layers? how many neurons on each layer? what is the activation function? what is the loss function? etc)\n",
    "\n",
    "Create at least 3 such networks and compare their performance (how accurate they are?, how farst they are trained to get at 1 accuracy?)\n",
    "\n",
    "Display for the best one the weights for each layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3614e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "tensor([[0.2363, 0.7747],\n",
      "        [0.1751, 0.0125]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "if torch.cuda.is_available():\n",
    "    my_device = torch.device('cuda')\n",
    "else:\n",
    "    my_device = torch.device('cpu')\n",
    "print('Device: {}'.format(my_device))\n",
    "\n",
    "x = torch.rand(2, 2, device=my_device)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e4cac31f-451b-4288-b6f1-fbf8bac573aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with learning rate: 0.1\n",
      "Epoch [100/5000], Loss: 0.0344\n",
      "Epoch [200/5000], Loss: 0.0291\n",
      "Epoch [300/5000], Loss: 0.0281\n",
      "Epoch [400/5000], Loss: 0.0277\n",
      "Epoch [500/5000], Loss: 0.0275\n",
      "Epoch [600/5000], Loss: 0.0273\n",
      "Epoch [700/5000], Loss: 0.0272\n",
      "Epoch [800/5000], Loss: 0.0272\n",
      "Epoch [900/5000], Loss: 0.0272\n",
      "Epoch [1000/5000], Loss: 0.0272\n",
      "Epoch [1100/5000], Loss: 0.0272\n",
      "Epoch [1200/5000], Loss: 0.0272\n",
      "Epoch [1300/5000], Loss: 0.0272\n",
      "Epoch [1400/5000], Loss: 0.0272\n",
      "Epoch [1500/5000], Loss: 0.0272\n",
      "Epoch [1600/5000], Loss: 0.0272\n",
      "Epoch [1700/5000], Loss: 0.0272\n",
      "Epoch [1800/5000], Loss: 0.0272\n",
      "Epoch [1900/5000], Loss: 0.0272\n",
      "Epoch [2000/5000], Loss: 0.0272\n",
      "Epoch [2100/5000], Loss: 0.0272\n",
      "Epoch [2200/5000], Loss: 0.0272\n",
      "Epoch [2300/5000], Loss: 0.0272\n",
      "Epoch [2400/5000], Loss: 0.0272\n",
      "Epoch [2500/5000], Loss: 0.0272\n",
      "Epoch [2600/5000], Loss: 0.0272\n",
      "Epoch [2700/5000], Loss: 0.0272\n",
      "Epoch [2800/5000], Loss: 0.0272\n",
      "Epoch [2900/5000], Loss: 0.0273\n",
      "Epoch [3000/5000], Loss: 0.0272\n",
      "Epoch [3100/5000], Loss: 0.0273\n",
      "Epoch [3200/5000], Loss: 0.0273\n",
      "Epoch [3300/5000], Loss: 0.0273\n",
      "Epoch [3400/5000], Loss: 0.0272\n",
      "Epoch [3500/5000], Loss: 0.0272\n",
      "Epoch [3600/5000], Loss: 0.0272\n",
      "Epoch [3700/5000], Loss: 0.0274\n",
      "Epoch [3800/5000], Loss: 0.0273\n",
      "Epoch [3900/5000], Loss: 0.0274\n",
      "Epoch [4000/5000], Loss: 0.0272\n",
      "Epoch [4100/5000], Loss: 0.0272\n",
      "Epoch [4200/5000], Loss: 0.0273\n",
      "Epoch [4300/5000], Loss: 0.0273\n",
      "Epoch [4400/5000], Loss: 0.0274\n",
      "Epoch [4500/5000], Loss: 0.0272\n",
      "Epoch [4600/5000], Loss: 0.0273\n",
      "Epoch [4700/5000], Loss: 0.0273\n",
      "Epoch [4800/5000], Loss: 0.0273\n",
      "Epoch [4900/5000], Loss: 0.0273\n",
      "Epoch [5000/5000], Loss: 0.0273\n",
      "Accuracy: 100.00%\n",
      "\n",
      "Training with learning rate: 0.01\n",
      "Epoch [100/5000], Loss: 1.2738\n",
      "Epoch [200/5000], Loss: 0.5883\n",
      "Epoch [300/5000], Loss: 0.5749\n",
      "Epoch [400/5000], Loss: 0.5644\n",
      "Epoch [500/5000], Loss: 0.5537\n",
      "Epoch [600/5000], Loss: 0.5419\n",
      "Epoch [700/5000], Loss: 0.5288\n",
      "Epoch [800/5000], Loss: 0.5143\n",
      "Epoch [900/5000], Loss: 0.4983\n",
      "Epoch [1000/5000], Loss: 0.4808\n",
      "Epoch [1100/5000], Loss: 0.4618\n",
      "Epoch [1200/5000], Loss: 0.4416\n",
      "Epoch [1300/5000], Loss: 0.2721\n",
      "Epoch [1400/5000], Loss: 0.2085\n",
      "Epoch [1500/5000], Loss: 0.1225\n",
      "Epoch [1600/5000], Loss: 0.0868\n",
      "Epoch [1700/5000], Loss: 0.0729\n",
      "Epoch [1800/5000], Loss: 0.0637\n",
      "Epoch [1900/5000], Loss: 0.0575\n",
      "Epoch [2000/5000], Loss: 0.0530\n",
      "Epoch [2100/5000], Loss: 0.0497\n",
      "Epoch [2200/5000], Loss: 0.0473\n",
      "Epoch [2300/5000], Loss: 0.0454\n",
      "Epoch [2400/5000], Loss: 0.0439\n",
      "Epoch [2500/5000], Loss: 0.0427\n",
      "Epoch [2600/5000], Loss: 0.0417\n",
      "Epoch [2700/5000], Loss: 0.0410\n",
      "Epoch [2800/5000], Loss: 0.0403\n",
      "Epoch [2900/5000], Loss: 0.0398\n",
      "Epoch [3000/5000], Loss: 0.0393\n",
      "Epoch [3100/5000], Loss: 0.0390\n",
      "Epoch [3200/5000], Loss: 0.0386\n",
      "Epoch [3300/5000], Loss: 0.0384\n",
      "Epoch [3400/5000], Loss: 0.0381\n",
      "Epoch [3500/5000], Loss: 0.0379\n",
      "Epoch [3600/5000], Loss: 0.0378\n",
      "Epoch [3700/5000], Loss: 0.0376\n",
      "Epoch [3800/5000], Loss: 0.0375\n",
      "Epoch [3900/5000], Loss: 0.0373\n",
      "Epoch [4000/5000], Loss: 0.0372\n",
      "Epoch [4100/5000], Loss: 0.0371\n",
      "Epoch [4200/5000], Loss: 0.0371\n",
      "Epoch [4300/5000], Loss: 0.0370\n",
      "Epoch [4400/5000], Loss: 0.0369\n",
      "Epoch [4500/5000], Loss: 0.0369\n",
      "Epoch [4600/5000], Loss: 0.0368\n",
      "Epoch [4700/5000], Loss: 0.0368\n",
      "Epoch [4800/5000], Loss: 0.0367\n",
      "Epoch [4900/5000], Loss: 0.0367\n",
      "Epoch [5000/5000], Loss: 0.0366\n",
      "Accuracy: 100.00%\n",
      "\n",
      "Training with learning rate: 0.001\n",
      "Epoch [100/5000], Loss: 2.2749\n",
      "Epoch [200/5000], Loss: 2.0748\n",
      "Epoch [300/5000], Loss: 1.8919\n",
      "Epoch [400/5000], Loss: 1.7398\n",
      "Epoch [500/5000], Loss: 1.6174\n",
      "Epoch [600/5000], Loss: 1.5126\n",
      "Epoch [700/5000], Loss: 1.4161\n",
      "Epoch [800/5000], Loss: 1.3222\n",
      "Epoch [900/5000], Loss: 1.2256\n",
      "Epoch [1000/5000], Loss: 1.1210\n",
      "Epoch [1100/5000], Loss: 1.0033\n",
      "Epoch [1200/5000], Loss: 0.8697\n",
      "Epoch [1300/5000], Loss: 0.7259\n",
      "Epoch [1400/5000], Loss: 0.5959\n",
      "Epoch [1500/5000], Loss: 0.5137\n",
      "Epoch [1600/5000], Loss: 0.4763\n",
      "Epoch [1700/5000], Loss: 0.4596\n",
      "Epoch [1800/5000], Loss: 0.4499\n",
      "Epoch [1900/5000], Loss: 0.4429\n",
      "Epoch [2000/5000], Loss: 0.4371\n",
      "Epoch [2100/5000], Loss: 0.4323\n",
      "Epoch [2200/5000], Loss: 0.4283\n",
      "Epoch [2300/5000], Loss: 0.4249\n",
      "Epoch [2400/5000], Loss: 0.4220\n",
      "Epoch [2500/5000], Loss: 0.4195\n",
      "Epoch [2600/5000], Loss: 0.4173\n",
      "Epoch [2700/5000], Loss: 0.4152\n",
      "Epoch [2800/5000], Loss: 0.4133\n",
      "Epoch [2900/5000], Loss: 0.4114\n",
      "Epoch [3000/5000], Loss: 0.4096\n",
      "Epoch [3100/5000], Loss: 0.4078\n",
      "Epoch [3200/5000], Loss: 0.4060\n",
      "Epoch [3300/5000], Loss: 0.4043\n",
      "Epoch [3400/5000], Loss: 0.4026\n",
      "Epoch [3500/5000], Loss: 0.4010\n",
      "Epoch [3600/5000], Loss: 0.3994\n",
      "Epoch [3700/5000], Loss: 0.3978\n",
      "Epoch [3800/5000], Loss: 0.3963\n",
      "Epoch [3900/5000], Loss: 0.3948\n",
      "Epoch [4000/5000], Loss: 0.3934\n",
      "Epoch [4100/5000], Loss: 0.3920\n",
      "Epoch [4200/5000], Loss: 0.3906\n",
      "Epoch [4300/5000], Loss: 0.3893\n",
      "Epoch [4400/5000], Loss: 0.3881\n",
      "Epoch [4500/5000], Loss: 0.3869\n",
      "Epoch [4600/5000], Loss: 0.3857\n",
      "Epoch [4700/5000], Loss: 0.3846\n",
      "Epoch [4800/5000], Loss: 0.3836\n",
      "Epoch [4900/5000], Loss: 0.3826\n",
      "Epoch [5000/5000], Loss: 0.3816\n",
      "Accuracy: 75.00%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "class AdderModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AdderModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 2)  # Input layer: 2 neurons, Hidden layer: 2 neurons\n",
    "        self.fc2 = nn.Linear(2, 2)  # Hidden layer: 2 neurons, Output layer: 2 neurons\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))  # ReLU activation for the hidden layer\n",
    "        x = torch.sigmoid(self.fc2(x))  # Sigmoid activation for the output layer\n",
    "        return x\n",
    "\n",
    "# Define dataset\n",
    "X_train = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "y_train = torch.tensor([[0, 0], [0, 1], [0, 1], [1, 0]], dtype=torch.float32)\n",
    "\n",
    "# Instantiate model\n",
    "model = AdderModel()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "\n",
    "# Try different learning rates\n",
    "learning_rates = [0.1, 0.01, 0.001]\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nTraining with learning rate: {lr}\")\n",
    "\n",
    "    # Initialize model weights using Xavier initialization\n",
    "    def weights_init(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    model.apply(weights_init)\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)  # Adam optimizer\n",
    "\n",
    "    # Training\n",
    "    num_epochs = 5000  # Increased number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "\n",
    "        # Apply L2 regularization\n",
    "        l2_reg = None\n",
    "        for param in model.parameters():\n",
    "            if l2_reg is None:\n",
    "                l2_reg = param.norm(2)\n",
    "            else:\n",
    "                l2_reg = l2_reg + param.norm(2)\n",
    "        loss = loss + 0.001 * l2_reg  # Regularization strength: 0.001\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient Clipping to prevent exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Max norm: 1.0\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Test the model\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_train)\n",
    "        predicted_labels = torch.round(predictions)  # Round the predictions to get binary labels (0 or 1)\n",
    "        correct = (predicted_labels == y_train).sum().item()\n",
    "        total = y_train.numel()  # Total number of elements in y_train\n",
    "        accuracy = correct / total\n",
    "        print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "58cee7ea-bc01-488d-b6cc-026441567acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with learning rate: 0.1\n",
      "Epoch [100/1000], Loss: 0.1738\n",
      "Epoch [200/1000], Loss: 0.0253\n",
      "Epoch [300/1000], Loss: 0.0244\n",
      "Epoch [400/1000], Loss: 0.0242\n",
      "Epoch [500/1000], Loss: 0.0241\n",
      "Epoch [600/1000], Loss: 0.0240\n",
      "Epoch [700/1000], Loss: 0.0240\n",
      "Epoch [800/1000], Loss: 0.0240\n",
      "Epoch [900/1000], Loss: 0.0240\n",
      "Epoch [1000/1000], Loss: 0.0241\n",
      "Accuracy: 100.00%\n",
      "\n",
      "Training with learning rate: 0.01\n",
      "Epoch [100/1000], Loss: 0.0240\n",
      "Epoch [200/1000], Loss: 0.0239\n",
      "Epoch [300/1000], Loss: 0.0239\n",
      "Epoch [400/1000], Loss: 0.0240\n",
      "Epoch [500/1000], Loss: 0.0240\n",
      "Epoch [600/1000], Loss: 0.0240\n",
      "Epoch [700/1000], Loss: 0.0240\n",
      "Epoch [800/1000], Loss: 0.0240\n",
      "Epoch [900/1000], Loss: 0.0240\n",
      "Epoch [1000/1000], Loss: 0.0239\n",
      "Accuracy: 100.00%\n",
      "\n",
      "Training with learning rate: 0.001\n",
      "Epoch [100/1000], Loss: 0.0239\n",
      "Epoch [200/1000], Loss: 0.0239\n",
      "Epoch [300/1000], Loss: 0.0239\n",
      "Epoch [400/1000], Loss: 0.0239\n",
      "Epoch [500/1000], Loss: 0.0239\n",
      "Epoch [600/1000], Loss: 0.0239\n",
      "Epoch [700/1000], Loss: 0.0239\n",
      "Epoch [800/1000], Loss: 0.0239\n",
      "Epoch [900/1000], Loss: 0.0239\n",
      "Epoch [1000/1000], Loss: 0.0239\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Attempt 1\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import OrderedDict\n",
    "\n",
    "X_train = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "y_train = torch.tensor([[0, 0], [0, 1], [0, 1], [1, 0]], dtype=torch.float32)\n",
    "\n",
    "model = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(2, 2)),\n",
    "    ('relu', nn.ReLU()),  # ReLU activation\n",
    "    ('fc2', nn.Linear(2, 2)),\n",
    "    ('sigmoid', nn.Sigmoid())  # Sigmoid activation\n",
    "]))\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        \n",
    "model.apply(weights_init)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "learning_rates = [0.1, 0.01, 0.001]\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nTraining with learning rate: {lr}\")\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    num_epochs = 1000\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "\n",
    "        l2_reg = None\n",
    "        for param in model.parameters():\n",
    "            if l2_reg is None:\n",
    "                l2_reg = param.norm(2)\n",
    "            else:\n",
    "                l2_reg = l2_reg + param.norm(2)\n",
    "        loss = loss + 0.001 * l2_reg\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_train)\n",
    "        predicted_labels = torch.round(predictions)\n",
    "        correct = (predicted_labels == y_train).sum().item()\n",
    "        total = y_train.numel()\n",
    "        accuracy = correct / total\n",
    "        print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "f39c71ea-cdcb-4d73-938e-eb959edc7613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with learning rate: 0.1\n",
      "Epoch [5/50], Loss: 0.0000\n",
      "Epoch [10/50], Loss: 0.0000\n",
      "Epoch [15/50], Loss: 0.0000\n",
      "Epoch [20/50], Loss: 0.0000\n",
      "Epoch [25/50], Loss: 0.0000\n",
      "Epoch [30/50], Loss: 0.0000\n",
      "Epoch [35/50], Loss: 0.0000\n",
      "Epoch [40/50], Loss: 0.0000\n",
      "Epoch [45/50], Loss: 0.0000\n",
      "Epoch [50/50], Loss: 0.0000\n",
      "Accuracy: 100.00%\n",
      "Model Parameters:\n",
      "fc1.weight tensor([[-0.3826, -0.5174],\n",
      "        [ 0.3124, -0.2854],\n",
      "        [ 0.0867,  0.5934]])\n",
      "fc1.bias tensor([-0.4885,  0.1310,  0.1114])\n",
      "fc2.weight tensor([[-0.0334, -0.5586,  0.1379],\n",
      "        [ 0.2959,  0.0308,  0.4329],\n",
      "        [ 0.4772, -0.1475, -0.3903]])\n",
      "fc2.bias tensor([-0.3393,  0.0645,  0.2708])\n",
      "fc3.weight tensor([[ 0.2204,  0.3110, -0.5230],\n",
      "        [ 0.0096, -0.2126, -0.4429]])\n",
      "fc3.bias tensor([-0.5058,  0.0303])\n",
      "\n",
      "Training with learning rate: 0.01\n",
      "Epoch [5/50], Loss: 0.0000\n",
      "Epoch [10/50], Loss: 0.0000\n",
      "Epoch [15/50], Loss: 0.0000\n",
      "Epoch [20/50], Loss: 0.0000\n",
      "Epoch [25/50], Loss: 0.0000\n",
      "Epoch [30/50], Loss: 0.0000\n",
      "Epoch [35/50], Loss: 0.0000\n",
      "Epoch [40/50], Loss: 0.0000\n",
      "Epoch [45/50], Loss: 0.0000\n",
      "Epoch [50/50], Loss: 0.0000\n",
      "Accuracy: 100.00%\n",
      "Model Parameters:\n",
      "fc1.weight tensor([[-0.3826, -0.5174],\n",
      "        [ 0.3124, -0.2854],\n",
      "        [ 0.0867,  0.5934]])\n",
      "fc1.bias tensor([-0.4885,  0.1310,  0.1114])\n",
      "fc2.weight tensor([[-0.0334, -0.5586,  0.1379],\n",
      "        [ 0.2959,  0.0308,  0.4329],\n",
      "        [ 0.4772, -0.1475, -0.3903]])\n",
      "fc2.bias tensor([-0.3393,  0.0645,  0.2708])\n",
      "fc3.weight tensor([[ 0.2204,  0.3110, -0.5230],\n",
      "        [ 0.0096, -0.2126, -0.4429]])\n",
      "fc3.bias tensor([-0.5058,  0.0303])\n",
      "\n",
      "Training with learning rate: 0.001\n",
      "Epoch [5/50], Loss: 0.0000\n",
      "Epoch [10/50], Loss: 0.0000\n",
      "Epoch [15/50], Loss: 0.0000\n",
      "Epoch [20/50], Loss: 0.0000\n",
      "Epoch [25/50], Loss: 0.0000\n",
      "Epoch [30/50], Loss: 0.0000\n",
      "Epoch [35/50], Loss: 0.0000\n",
      "Epoch [40/50], Loss: 0.0000\n",
      "Epoch [45/50], Loss: 0.0000\n",
      "Epoch [50/50], Loss: 0.0000\n",
      "Accuracy: 100.00%\n",
      "Model Parameters:\n",
      "fc1.weight tensor([[-0.3826, -0.5174],\n",
      "        [ 0.3124, -0.2854],\n",
      "        [ 0.0867,  0.5934]])\n",
      "fc1.bias tensor([-0.4885,  0.1310,  0.1114])\n",
      "fc2.weight tensor([[-0.0334, -0.5586,  0.1379],\n",
      "        [ 0.2959,  0.0308,  0.4329],\n",
      "        [ 0.4772, -0.1475, -0.3903]])\n",
      "fc2.bias tensor([-0.3393,  0.0645,  0.2708])\n",
      "fc3.weight tensor([[ 0.2204,  0.3110, -0.5230],\n",
      "        [ 0.0096, -0.2126, -0.4429]])\n",
      "fc3.bias tensor([-0.5058,  0.0303])\n"
     ]
    }
   ],
   "source": [
    "# Attempt 2, best one\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import OrderedDict\n",
    "\n",
    "X_train = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "y_train = torch.tensor([[0, 0], [0, 1], [0, 1], [1, 0]], dtype=torch.float32)\n",
    "\n",
    "new_model = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(2, 3)),\n",
    "    ('relu', nn.ReLU()),\n",
    "    ('fc2', nn.Linear(3, 3)),\n",
    "    ('relu', nn.Tanh()),\n",
    "    ('fc3', nn.Linear(3, 2)),\n",
    "    ('sigmoid', nn.Sigmoid())\n",
    "]))\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "learning_rates = [0.1, 0.01, 0.001]\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nTraining with learning rate: {lr}\")\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    num_epochs = 50\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch+1) % 5 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_train)\n",
    "        predicted_labels = torch.round(predictions)\n",
    "        correct = (predicted_labels == y_train).sum().item()\n",
    "        total = y_train.numel()\n",
    "        accuracy = correct / total\n",
    "        print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "        print(\"Model Parameters:\")\n",
    "        for name, param in new_model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(name, param.data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c5e7df7a-b4b6-4832-b241-1393e3a3137a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with learning rate: 0.1\n",
      "Epoch [5/100], Loss: 0.5790\n",
      "Epoch [10/100], Loss: 0.4498\n",
      "Epoch [15/100], Loss: 0.3305\n",
      "Epoch [20/100], Loss: 0.1968\n",
      "Epoch [25/100], Loss: 0.1056\n",
      "Epoch [30/100], Loss: 0.0553\n",
      "Epoch [35/100], Loss: 0.0295\n",
      "Epoch [40/100], Loss: 0.0170\n",
      "Epoch [45/100], Loss: 0.0104\n",
      "Epoch [50/100], Loss: 0.0071\n",
      "Epoch [55/100], Loss: 0.0051\n",
      "Epoch [60/100], Loss: 0.0041\n",
      "Epoch [65/100], Loss: 0.0034\n",
      "Epoch [70/100], Loss: 0.0029\n",
      "Epoch [75/100], Loss: 0.0026\n",
      "Epoch [80/100], Loss: 0.0023\n",
      "Epoch [85/100], Loss: 0.0021\n",
      "Epoch [90/100], Loss: 0.0020\n",
      "Epoch [95/100], Loss: 0.0018\n",
      "Epoch [100/100], Loss: 0.0017\n",
      "Accuracy: 100.00%\n",
      "\n",
      "Training with learning rate: 0.01\n",
      "Epoch [5/100], Loss: 0.0016\n",
      "Epoch [10/100], Loss: 0.0014\n",
      "Epoch [15/100], Loss: 0.0012\n",
      "Epoch [20/100], Loss: 0.0011\n",
      "Epoch [25/100], Loss: 0.0010\n",
      "Epoch [30/100], Loss: 0.0009\n",
      "Epoch [35/100], Loss: 0.0008\n",
      "Epoch [40/100], Loss: 0.0007\n",
      "Epoch [45/100], Loss: 0.0006\n",
      "Epoch [50/100], Loss: 0.0006\n",
      "Epoch [55/100], Loss: 0.0005\n",
      "Epoch [60/100], Loss: 0.0005\n",
      "Epoch [65/100], Loss: 0.0004\n",
      "Epoch [70/100], Loss: 0.0004\n",
      "Epoch [75/100], Loss: 0.0004\n",
      "Epoch [80/100], Loss: 0.0004\n",
      "Epoch [85/100], Loss: 0.0003\n",
      "Epoch [90/100], Loss: 0.0003\n",
      "Epoch [95/100], Loss: 0.0003\n",
      "Epoch [100/100], Loss: 0.0003\n",
      "Accuracy: 100.00%\n",
      "\n",
      "Training with learning rate: 0.001\n",
      "Epoch [5/100], Loss: 0.0003\n",
      "Epoch [10/100], Loss: 0.0003\n",
      "Epoch [15/100], Loss: 0.0003\n",
      "Epoch [20/100], Loss: 0.0003\n",
      "Epoch [25/100], Loss: 0.0003\n",
      "Epoch [30/100], Loss: 0.0003\n",
      "Epoch [35/100], Loss: 0.0002\n",
      "Epoch [40/100], Loss: 0.0002\n",
      "Epoch [45/100], Loss: 0.0002\n",
      "Epoch [50/100], Loss: 0.0002\n",
      "Epoch [55/100], Loss: 0.0002\n",
      "Epoch [60/100], Loss: 0.0002\n",
      "Epoch [65/100], Loss: 0.0002\n",
      "Epoch [70/100], Loss: 0.0002\n",
      "Epoch [75/100], Loss: 0.0002\n",
      "Epoch [80/100], Loss: 0.0002\n",
      "Epoch [85/100], Loss: 0.0002\n",
      "Epoch [90/100], Loss: 0.0002\n",
      "Epoch [95/100], Loss: 0.0002\n",
      "Epoch [100/100], Loss: 0.0002\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Attempt 3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import OrderedDict\n",
    "\n",
    "X_train = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "y_train = torch.tensor([[0, 0], [0, 1], [0, 1], [1, 0]], dtype=torch.float32)\n",
    "\n",
    "\n",
    "model = nn.Sequential(OrderedDict([\n",
    "    ('fc1', nn.Linear(2, 5)),\n",
    "    ('relu', nn.ReLU()),\n",
    "    ('fc2', nn.Linear(5, 2)),\n",
    "    ('sigmoid', nn.Sigmoid())\n",
    "]))\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "model.apply(weights_init)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "learning_rates = [0.1, 0.01, 0.001]\n",
    "for lr in learning_rates:\n",
    "    print(f\"\\nTraining with learning rate: {lr}\")\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    num_epochs = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Max norm: 1.0\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch+1) % 5 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_train)\n",
    "        predicted_labels = torch.round(predictions)\n",
    "        correct = (predicted_labels == y_train).sum().item()\n",
    "        total = y_train.numel()\n",
    "        accuracy = correct / total\n",
    "        print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7efff4f6-4446-4972-a97c-d6959f6a2464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]])\n",
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_bits = pd.read_csv(\"bit_test.csv\")\n",
    "#X = data['input1'].astype(float)\n",
    "#y = data['input2'].astype(float)\n",
    "X=df_bits[['input1','input2']]\n",
    "#print(X)\n",
    "Y=df_bits[['output1','output2']]\n",
    "\n",
    "##df_bits.dropna(axis=1,inplace=True)\n",
    "#df_bits.isnull().sum()\n",
    "#print(df_bits.head())\n",
    "#print(data['input1'])\n",
    "data_in = torch.tensor(X[['input1', 'input2']].values).float()\n",
    "data_out = torch.tensor(Y[['output1', 'output2']].values).float()\n",
    "print(data_in)\n",
    "print(data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe8367a0-86d0-4fac-86b6-f5d740f61b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here\n",
    "model1 = nn.Sequential(OrderedDict([\n",
    "    ('hidden', nn.Linear(2,2)),\n",
    "    ('activation', nn.ReLU()),\n",
    "     ('output', nn.Linear(2,2))\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "665ae958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (hidden): Linear(in_features=2, out_features=2, bias=True)\n",
      "  (activation): ReLU()\n",
      "  (output): Linear(in_features=2, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e26f0d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "#data_in = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]]).float()\n",
    "print(data_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4fb16bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.],\n",
      "        [0., 1.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "#data_target = torch.tensor( ...\n",
    "print(data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "69d920ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model1.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "ec3d92a7-a148-4239-95cf-03de950de11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0037\n",
      "Epoch [200/1000], Loss: 0.0000\n",
      "Epoch [300/1000], Loss: 0.0000\n",
      "Epoch [400/1000], Loss: 0.0000\n",
      "Epoch [500/1000], Loss: 0.0000\n",
      "Epoch [600/1000], Loss: 0.0000\n",
      "Epoch [700/1000], Loss: 0.0000\n",
      "Epoch [800/1000], Loss: 0.0000\n",
      "Epoch [900/1000], Loss: 0.0000\n",
      "Epoch [1000/1000], Loss: 0.0000\n",
      "Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "model1 = nn.Sequential(OrderedDict([\n",
    "    ('hidden', nn.Linear(2,5)),\n",
    "    ('activation', nn.ReLU()),\n",
    "     ('output', nn.Linear(5,2))\n",
    "]))\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model1.parameters(), lr=0.2)\n",
    "\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model1(data_in)\n",
    "    loss = criterion(outputs, data_out)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "predicted_labels = torch.round(torch.sigmoid(model1(data_in))).detach().numpy()\n",
    "accuracy = (predicted_labels == data_out.detach().numpy()).mean()\n",
    "print('Accuracy:', accuracy.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "cde91f6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/2000], Loss: 0.0072\n",
      "Epoch [200/2000], Loss: 0.0007\n",
      "Epoch [300/2000], Loss: 0.0027\n",
      "Epoch [400/2000], Loss: 0.0000\n",
      "Epoch [500/2000], Loss: 0.0000\n",
      "Epoch [600/2000], Loss: 0.0000\n",
      "Epoch [700/2000], Loss: 0.0000\n",
      "Epoch [800/2000], Loss: 0.0000\n",
      "Epoch [900/2000], Loss: 0.0000\n",
      "Epoch [1000/2000], Loss: 0.0000\n",
      "Epoch [1100/2000], Loss: 0.0000\n",
      "Epoch [1200/2000], Loss: 0.0000\n",
      "Epoch [1300/2000], Loss: 0.0000\n",
      "Epoch [1400/2000], Loss: 0.0000\n",
      "Epoch [1500/2000], Loss: 0.0000\n",
      "Epoch [1600/2000], Loss: 0.0000\n",
      "Epoch [1700/2000], Loss: 0.0000\n",
      "Epoch [1800/2000], Loss: 0.0000\n",
      "Epoch [1900/2000], Loss: 0.0000\n",
      "Epoch [2000/2000], Loss: 0.0000\n",
      "Accuracy: 0.875\n"
     ]
    }
   ],
   "source": [
    "## your code here\n",
    "model2 = nn.Sequential(OrderedDict([\n",
    "    ('hidden', nn.Linear(2,5)),\n",
    "    ('activation', nn.Tanh()),\n",
    "     ('output', nn.Linear(5,2))\n",
    "]))\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model2.parameters(), lr=0.9)\n",
    "\n",
    "num_epochs = 2000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model2(data_in)\n",
    "    loss = criterion(outputs, data_out)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "predicted_labels = torch.round(torch.sigmoid(model2(data_in))).detach().numpy()\n",
    "accuracy = (predicted_labels == data_out.detach().numpy()).mean()\n",
    "print('Accuracy:', accuracy.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "dff3ec1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.1713\n",
      "Epoch [200/1000], Loss: 0.1691\n",
      "Epoch [300/1000], Loss: 0.1670\n",
      "Epoch [400/1000], Loss: 0.1649\n",
      "Epoch [500/1000], Loss: 0.1629\n",
      "Epoch [600/1000], Loss: 0.1609\n",
      "Epoch [700/1000], Loss: 0.1589\n",
      "Epoch [800/1000], Loss: 0.1569\n",
      "Epoch [900/1000], Loss: 0.1550\n",
      "Epoch [1000/1000], Loss: 0.1531\n",
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "model3 = nn.Sequential(OrderedDict([\n",
    "    ('hidden', nn.Linear(2, 4)),          # Adjust hidden layer size as needed\n",
    "    ('activation', nn.ReLU()),             # Use ReLU activation in the hidden layer\n",
    "    ('output', nn.Linear(4, 2)),          # Output layer with 2 neurons for 2-bit output\n",
    "    ('softmax', nn.Softmax(dim=1))        # Apply Softmax activation to output layer\n",
    "]))\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model3.parameters(), lr=0.002)\n",
    "\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model3(data_in)\n",
    "    loss = criterion(outputs, data_out)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "predicted_labels = torch.round(torch.sigmoid(model3(data_in))).detach().numpy()\n",
    "accuracy = (predicted_labels == data_out.detach().numpy()).mean()\n",
    "print('Accuracy:', accuracy.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "c1a7518b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/2000], Loss: 0.0629\n",
      "Epoch [200/2000], Loss: 0.0842\n",
      "Epoch [300/2000], Loss: 0.0621\n",
      "Epoch [400/2000], Loss: 0.0607\n",
      "Epoch [500/2000], Loss: 0.0571\n",
      "Epoch [600/2000], Loss: 0.0485\n",
      "Epoch [700/2000], Loss: 0.0072\n",
      "Epoch [800/2000], Loss: 0.0006\n",
      "Epoch [900/2000], Loss: 0.0000\n",
      "Epoch [1000/2000], Loss: 0.0000\n",
      "Epoch [1100/2000], Loss: 0.0000\n",
      "Epoch [1200/2000], Loss: 0.0000\n",
      "Epoch [1300/2000], Loss: 0.0000\n",
      "Epoch [1400/2000], Loss: 0.0000\n",
      "Epoch [1500/2000], Loss: 0.0000\n",
      "Epoch [1600/2000], Loss: 0.0000\n",
      "Epoch [1700/2000], Loss: 0.0000\n",
      "Epoch [1800/2000], Loss: 0.0000\n",
      "Epoch [1900/2000], Loss: 0.0000\n",
      "Epoch [2000/2000], Loss: 0.0000\n",
      "Accuracy: 0.625\n"
     ]
    }
   ],
   "source": [
    "model4 = nn.Sequential(OrderedDict([\n",
    "    ('hidden', nn.Linear(2, 3)),          # Adjust hidden layer size as needed\n",
    "    ('activation', nn.ELU()),             # Use ELU activation in the hidden layer\n",
    "    ('output', nn.Linear(3, 2))           # Output layer with 2 neurons for 2-bit output\n",
    "]))\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.SGD(model4.parameters(), lr=0.5)\n",
    "\n",
    "# Convert input and output data to torch tensors\n",
    "data_in = torch.tensor(X[['input1', 'input2']].values, dtype=torch.float32)\n",
    "data_out = torch.tensor(Y[['output1', 'output2']].values, dtype=torch.float32)\n",
    "\n",
    "num_epochs = 2000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = model4(data_in)\n",
    "    loss = criterion(outputs, data_out)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the loss every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate the trained model\n",
    "with torch.no_grad():\n",
    "    predicted_labels = torch.round(torch.sigmoid(model4(data_in))).detach().numpy()\n",
    "    accuracy = (predicted_labels == data_out.detach().numpy()).mean()\n",
    "    print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdf09ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bea66c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "e29c65a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model 1\n",
      "Epoch [100/1000], Loss: 0.0085\n",
      "Epoch [200/1000], Loss: 0.0001\n",
      "Epoch [300/1000], Loss: 0.0000\n",
      "Epoch [400/1000], Loss: 0.0000\n",
      "Epoch [500/1000], Loss: 0.0000\n",
      "Epoch [600/1000], Loss: 0.0000\n",
      "Epoch [700/1000], Loss: 0.0000\n",
      "Epoch [800/1000], Loss: 0.0000\n",
      "Epoch [900/1000], Loss: 0.0000\n",
      "Epoch [1000/1000], Loss: 0.0000\n",
      "Model 1 Accuracy: 0.625\n",
      "Training Model 2\n",
      "Epoch [100/1000], Loss: 0.1104\n",
      "Epoch [200/1000], Loss: 0.0094\n",
      "Epoch [300/1000], Loss: 0.0003\n",
      "Epoch [400/1000], Loss: 0.0000\n",
      "Epoch [500/1000], Loss: 0.0000\n",
      "Epoch [600/1000], Loss: 0.0000\n",
      "Epoch [700/1000], Loss: 0.0000\n",
      "Epoch [800/1000], Loss: 0.0000\n",
      "Epoch [900/1000], Loss: 0.0000\n",
      "Epoch [1000/1000], Loss: 0.0000\n",
      "Model 2 Accuracy: 0.75\n",
      "Training Model 3\n",
      "Epoch [100/1000], Loss: 0.2187\n",
      "Epoch [200/1000], Loss: 0.2187\n",
      "Epoch [300/1000], Loss: 0.2187\n",
      "Epoch [400/1000], Loss: 0.2187\n",
      "Epoch [500/1000], Loss: 0.2187\n",
      "Epoch [600/1000], Loss: 0.2186\n",
      "Epoch [700/1000], Loss: 0.2186\n",
      "Epoch [800/1000], Loss: 0.2186\n",
      "Epoch [900/1000], Loss: 0.2186\n",
      "Epoch [1000/1000], Loss: 0.2186\n",
      "Model 3 Accuracy: 0.375\n",
      "Layer: hidden.weight, Weights: tensor([[-0.8388,  0.9273],\n",
      "        [ 0.6401,  0.5245],\n",
      "        [ 0.9663, -0.9521],\n",
      "        [-0.1579, -0.2513],\n",
      "        [ 0.3885,  0.7240]])\n",
      "Layer: hidden.bias, Weights: tensor([ 1.4670e-09, -5.3065e-01, -1.2681e-08, -5.5054e-01,  4.7595e-01])\n",
      "Layer: output.weight, Weights: tensor([[-0.4608,  0.6129, -0.3067, -0.1195,  0.5902],\n",
      "        [ 0.8413, -0.6724,  0.9890, -0.3931,  0.3036]])\n",
      "Layer: output.bias, Weights: tensor([-0.2809, -0.1445])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Define dataset (inputs and outputs for adding two bits)\n",
    "data_in = torch.tensor([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=torch.float32)\n",
    "data_out = torch.tensor([[0, 0], [0, 1], [0, 1], [1, 0]], dtype=torch.float32)\n",
    "\n",
    "# Define model architectures\n",
    "models = []\n",
    "\n",
    "# Model 1\n",
    "model1 = nn.Sequential(OrderedDict([\n",
    "    ('hidden', nn.Linear(2, 5)),\n",
    "    ('activation', nn.ReLU()),\n",
    "    ('output', nn.Linear(5, 2))\n",
    "]))\n",
    "models.append(model1)\n",
    "\n",
    "# Model 2\n",
    "model2 = nn.Sequential(OrderedDict([\n",
    "    ('hidden1', nn.Linear(2, 4)),\n",
    "    ('activation1', nn.Tanh()),\n",
    "    ('hidden2', nn.Linear(4, 4)),\n",
    "    ('activation2', nn.Tanh()),\n",
    "    ('output', nn.Linear(4, 2))\n",
    "]))\n",
    "models.append(model2)\n",
    "\n",
    "# Model 3\n",
    "model3 = nn.Sequential(OrderedDict([\n",
    "    ('hidden1', nn.Linear(2, 3)),\n",
    "    ('activation1', nn.Sigmoid()),\n",
    "    ('hidden2', nn.Linear(3, 3)),\n",
    "    ('activation2', nn.Sigmoid()),\n",
    "    ('hidden3', nn.Linear(3, 3)),\n",
    "    ('activation3', nn.Sigmoid()),\n",
    "    ('output', nn.Linear(3, 2))\n",
    "]))\n",
    "models.append(model3)\n",
    "\n",
    "# Define criterion (loss function) and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizers = [optim.SGD(model.parameters(), lr=0.2) for model in models]\n",
    "\n",
    "# Train each model\n",
    "for i, model in enumerate(models):\n",
    "    print(f\"Training Model {i+1}\")\n",
    "    optimizer = optimizers[i]\n",
    "    for epoch in range(1000):\n",
    "        # Forward pass\n",
    "        outputs = model(data_in)\n",
    "        loss = criterion(outputs, data_out)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print the loss every 100 epochs\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/1000], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # Evaluate the trained model\n",
    "    with torch.no_grad():\n",
    "        predicted_labels = torch.round(torch.sigmoid(model(data_in))).detach().numpy()\n",
    "        accuracy = (predicted_labels == data_out.detach().numpy()).mean()\n",
    "        print(f'Model {i+1} Accuracy:', accuracy.item())\n",
    "\n",
    "# Display the weights for each layer of the best-performing model (highest accuracy)\n",
    "best_model_idx = max(range(len(models)), key=lambda i: accuracy)\n",
    "best_model = models[best_model_idx]\n",
    "for name, param in best_model.named_parameters():\n",
    "    print(f'Layer: {name}, Weights: {param.data}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25103c29-212a-4512-9262-a9fb642c02c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
